<!-- manual page source format generated by PolyglotMan v3.0.4, -->
<!-- available via anonymous ftp from ftp.cs.berkeley.edu:/ucb/people/phelps/tcltk/rman.tar.Z -->

<HTML>
<HEAD>
<TITLE>QccVIDMeshMotionEstimationSearch.3</TITLE>
</HEAD>
<BODY>
<A HREF="#toc">Table of Contents</A><P>
 
<H2><A NAME="sect0" HREF="#toc0">NAME </A></H2>
QccVIDMeshMotionEstimationWarpMesh, QccVIDMeshMotionEstimationSearch, 
QccVIDMeshMotionEstimationCreateCompensatedFrame - routines for motion 
estimation and compensation using regular triangle meshes  
<H2><A NAME="sect1" HREF="#toc1">SYNOPSIS </A></H2>
<B>#include 
"libQccPack.h"</B>  <P>
<B>int QccVIDMeshMotionEstimationWarpMesh(const QccRegularMesh 
*</B><I>reference_mesh</I><B>, QccRegularMesh *</B><I>current_mesh</I><B>, const QccIMGImageComponent 
*</B><I>motion_vectors_horizontal</I><B>, const QccIMGImageComponent *</B><I>motion_vectors_vertical</I><B>);</B> 
 <BR>
 <P>
<B>int QccVIDMeshMotionEstimationSearch(const QccIMGImageComponent *</B><I>current_frame</I><B>, 
QccRegularMesh *</B><I>current_mesh</I><B>, const QccIMGImageComponent *</B><I>reference_frame</I><B>, 
const QccRegularMesh *</B><I>reference_mesh</I><B>, QccIMGImageComponent *</B><I>motion_vectors_horizontal</I><B>, 
QccIMGImageComponent *</B><I>motion_vectors_vertical</I><B>, int </B><I>block_size</I><B>, int </B><I>window_size</I><B>, 
int </B><I>subpixel_accuracy</I><B>, int </B><I>constrained_boundary</I><B>, int </B><I>exponential_kernel</I><B>);</B> 
 <BR>
 <P>
<B>int QccVIDMeshMotionEstimationCreateCompensatedFrame(QccIMGImageComponent 
*</B><I>motion_compensated_frame</I><B>, const QccRegularMesh *</B><I>current_mesh</I><B>, const QccIMGImageComponent 
*</B><I>reference_frame</I><B>, const QccRegularMesh *</B><I>reference_mesh</I><B>, int </B><I>subpixel_accuracy</I><B>);</B> 
 
<H2><A NAME="sect2" HREF="#toc2">DESCRIPTION </A></H2>
<B>QccVIDMeshMotionEstimationSearch()</B> and <B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B> 
perform motion estimation and compensation, respectively, between two 
video frames using a regular triangle mesh rather than square blocks as 
in the ubiquitous block-based motion estimation/compensation (i.e., see <B><A HREF="QccVIDMotionEstimationFullSearch.3.html">QccVIDMotionEstimationFullSearch</B>(3)</A>
). 
This regular triangle mesh is created by dividing the reference frame 
into square blocks and then splitting each block along its diagonal. <P>
For 
motion estimation via <B>QccVIDMeshMotionEstimationSearch()</B>, the triangle 
vertices, or "control points," of the regular mesh are tracked from the 
reference frame to the current frame via a simple, block-based motion-estimation 
strategy due to Eckert <I>et al</I>. In this approach, motion into the current 
frame is estimated by centering a small block at each vertex in the reference-frame 
mesh and finding the best-matching block in the current frame. <P>
Once motion 
is estimated in this manner and a field of motion vectors determined, 
<B>QccVIDMeshMotionEstimationWarpMesh()</B> can be used to create a motion-compensated 
version of the mesh in the current frame from the mesh in the reference 
frame. In essence, <B>QccVIDMeshMotionEstimationWarpMesh()</B> "warps" the reference-frame 
mesh into the current frame by adding to each vertex of the mesh its corresponding 
motion vector. <P>
Once the motion-compensated mesh is available in the current 
frame, <B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B> can be used 
to perform motion compensation between the frames. That is, <B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B> 
uses affine transforms between the two meshes to construct a motion-compensated 
prediction of the current frame from the reference frame. This motion-compensated 
frame is constructed by creating, for each triangle in the reference-frame 
mesh, an affine transform that maps the triangle into the current-frame 
mesh. This affine transform is then used to map the pixels corresponding 
to the triangle in the reference frame into the current frame, with bilinear 
interpolation between the surrounding four integer-pixel locations used 
to resolve subpixel positions produced by the affine mapping.  
<H3><A NAME="sect3" HREF="#toc3">Motion Estimation 
</A></H3>
<B>QccVIDMeshMotionEstimationSearch()</B> performs a motion-estimation search 
to produce a motion-vector field between <I>reference_frame</I> and <I>current_frame</I>. 
<I>reference_mesh</I> is the regular mesh in the reference frame, and <B>QccVIDMeshMotionEstimationSearch()</B> 
estimates the motion of the vertices of this mesh, producing a motion-vector 
field which is returned in <I>motion_vectors_horizontal</I> and <I>motion_vectors_vertical</I>. 
<B>QccVIDMeshMotionEstimationSearch()</B> calls <B>QccVIDMeshMotionEstimationWarpMesh()</B> 
(see below) to produce the corresponding motion-compensated mesh in the 
current frame, which is returned as <I>current_mesh</I>. <P>
<I>block_size</I> gives the 
the size of the square block that is centered at each mesh vertex in order 
to determine the vertex motion, following the block-based vertex-motion 
estimation procedure outlined by Eckert <I>et al</I>. <P>
<I>window_size</I> gives the size 
of the motion-estimation search window about the current vertex location. 
<P>
<I>subpixel_accuracy</I> is one of <B>QCCVID_ME_FULLPIXEL</B>, <B>QCCVID_ME_HALFPIXEL</B>, 
<B>QCCVID_ME_QUARTERPIXEL</B>, or  <B>QCCVID_ME_EIGHTHPIXEL</B>, indicating full-, half-, 
quarter-, or eighth-pixel accuracy. If anything other than integer-pixel accuracy 
is used, <B><A HREF="QccVIDMotionEstimationCreateReferenceFrame.3.html">QccVIDMotionEstimationCreateReferenceFrame</B>(3)</A>
 must be called 
on both <I>current_frame</I> and <I>reference_frame</I> to interpolate them to the appropriate 
subpixel accuracy prior to calling <B>QccVIDMeshMotionEstimationSearch()</B>. 
<P>
If <I>constrained_boundary</I> is 1,  <B>QccVIDMeshMotionEstimationSearch()</B> constrains 
all vertices that lie on the boundary of the reference frame to have zero-valued 
motion vectors. In doing so, the resulting <I>current_mesh</I> is guaranteed to 
cover the entire <I>current_frame</I> with no "gaps." If <I>constrained_boundary</I> 
is 0, no such guarantee is in place, and motion vectors for the image-boundary 
vertices can take on any value, perhaps moving into the interior of the 
image or beyond the bounds of the image. This latter, unconstrained approach 
may permit better motion estimation at the expense of some "gaps" possibly 
arising in the corresponding motion-compensated frame. <P>
If <I>exponential_kernel</I> 
is 1, a exponential function is used to create a kernel for the block-based 
search process that estimates the motion of the mesh vertices. This exponential 
kernel provides greater weight to the pixels in the center of the block 
(i.e., corresponding to the vertex of interest itself) and exponentially 
decreasing weight to pixels distant from the center. If <I>exponential_kernel</I> 
is 0, all pixels in the block are weighted the same in the motion-estimation 
search. See Eckert <I>et al</I>. and Schroder and Mech.  
<H3><A NAME="sect4" HREF="#toc4">Motion Compensation </A></H3>
<B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B> 
constructs the motion-compensated prediction of the current frame from 
<I>reference_frame</I> using affine transforms between the reference-frame mesh, 
<I>reference_mesh</I>, and the current-frame mesh, <I>current_mesh</I>. The motion-compensated 
frame is returned in <I>motion_compensated_frame</I>, which must be allocated 
prior to calling <B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B>. <P>
<I>subpixel_accuracy</I> 
is one of <B>QCCVID_ME_FULLPIXEL</B>, <B>QCCVID_ME_HALFPIXEL</B>, <B>QCCVID_ME_QUARTERPIXEL</B>, 
or  <B>QCCVID_ME_EIGHTHPIXEL</B>, indicating full-, half-, quarter-, or eighth-pixel 
accuracy. If anything other than integer-pixel accuracy is used, <B><A HREF="QccVIDMotionEstimationCreateReferenceFrame.3.html">QccVIDMotionEstimationCreateReferenceFrame</B>(3)</A>
 
must be called on <I>reference_frame</I> to interpolate it to the appropriate 
subpixel accuracy prior to calling <B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B>. 
On the other hand, <I>motion_compensated_frame</I> must be the same size as the 
original current and reference frames in all cases (i.e., it is not interpolated 
to subpixel accuracy). <P>
<B>QccVIDMeshMotionEstimationCreateCompensatedFrame()</B> 
uses <B><A HREF="QccTriangleCreateAffineTransform.3.html">QccTriangleCreateAffineTransform</B>(3)</A>
 to construct an affine transform 
between each pair of reference-frame and current-frame triangles, and <B><A HREF="QccPointAffineTransform.3.html">QccPointAffineTransform</B>(3)</A>
 
to map a pixel from the reference frame to the current frame.  
<H3><A NAME="sect5" HREF="#toc5">Mesh Warping 
</A></H3>
<B>QccVIDMeshMotionEstimationWarpMesh()</B> constructs a mesh in the current 
frame, <I>current_mesh</I>, from a mesh in the reference frame, <I>reference_mesh</I>, 
by adding motion vectors to each vertex of <I>reference_mesh</I>. The motion vectors 
are specified by <I>motion_vectors_horizontal</I> and <I>motion_vectors_vertical</I> 
and are usually obtained via <B>QccVIDMeshMotionEstimationSearch()</B>. <I>current_mesh</I> 
must be allocated to the same size as <I>reference_mesh</I> prior to calling 
<B>QccVIDMeshMotionEstimationWarpMesh()</B>.  
<H2><A NAME="sect6" HREF="#toc6">RETURN VALUE </A></H2>
These routines return 
0 on success, and 1 on failure.  
<H2><A NAME="sect7" HREF="#toc7">SEE ALSO </A></H2>
<B><A HREF="QccVIDMotionVectorsEncode.3.html">QccVIDMotionVectorsEncode</B>(3)</A>
, 
<B><A HREF="QccVIDMotionVectorsDecode.3.html">QccVIDMotionVectorsDecode</B>(3)</A>
, <B><A HREF="QccRegularMesh.3.html">QccRegularMesh</B>(3)</A>
, <B><A HREF="mesh_memc.1.html">mesh_memc</B>(1)</A>
, <B><A HREF="QccPackVID.3.html">QccPackVID</B>(3)</A>
, 
<B><A HREF="QccPackENT.3.html">QccPackENT</B>(3)</A>
, <B><A HREF="QccPack.3.html">QccPack</B>(3)</A>
 <P>
 Y. Altunbasak, A. M. Tekalp, and G. Bozdagi, "Two-Dimensional 
Object-based Coding Using a Content-based Mesh and Affine Motion Parameterization," 
in <I>Proceedings of the International Conference on Image Processing</I>, Washington, 
DC, October 1995, vol. 2, pp. 394-397. <P>
 M. Eckert, D. Ruiz, J. I. Ronda, and N. 
Garcia, "Evaluation of DWT and DCT for Irregular Mesh-based Motion Compensation 
in Predictive Video Coding,"  in <I>Visual Communications and Image Processing</I>, 
K. N. Ngan, T. Sikora, and M.-T. Sun, Eds., Proc. SPIE 4067, June 2000, pp. 447-456. 
<P>
 K. Schroder and R. Mech, "Combined Description of Shape and Motion in an 
Object Based Coding Scheme Using Curved Triangles," in <I>Proceedings of 
the International Conference on Image Processing</I>, Washington, DC, October 
1995, vol. 2, pp. 390-393. <P>
 Y. Wang, S. Cui, and J. E. Fowler, "3D Video Coding 
Using Redundant-Wavelet Multihypothesis and Motion-Compensated Temporal 
Filtering," in <I>Proceedings of the International Conference on Image Processing</I>, 
Barcelona, Spain, September 2003, vol. 2, pp. 755-758. <P>
 Y. Wang, S. Cui, and 
J. E. Fowler, "3D Video Coding with Redundant-Wavelet Multihypothesis," <I>IEEE 
Transactions on Circuits and Systems for Video Technology</I>, submitted July 
2003. Revised April 2004, March 2005. <P>
  
<H2><A NAME="sect8" HREF="#toc8">AUTHOR </A></H2>
Copyright (C) 1997-2016  James 
E. Fowler <P>
 <P>

<HR><P>
<A NAME="toc"><B>Table of Contents</B></A><P>
<UL>
<LI><A NAME="toc0" HREF="#sect0">NAME</A></LI>
<LI><A NAME="toc1" HREF="#sect1">SYNOPSIS</A></LI>
<LI><A NAME="toc2" HREF="#sect2">DESCRIPTION</A></LI>
<UL>
<LI><A NAME="toc3" HREF="#sect3">Motion Estimation</A></LI>
<LI><A NAME="toc4" HREF="#sect4">Motion Compensation</A></LI>
<LI><A NAME="toc5" HREF="#sect5">Mesh Warping</A></LI>
</UL>
<LI><A NAME="toc6" HREF="#sect6">RETURN VALUE</A></LI>
<LI><A NAME="toc7" HREF="#sect7">SEE ALSO</A></LI>
<LI><A NAME="toc8" HREF="#sect8">AUTHOR</A></LI>
</UL>
<p><br><br><a href="http://sourceforge.net/projects/qccpack"><img src="http://sflogo.sourceforge.net/sflogo.php?group_id=5992&type=6" width="210" height="62" border="0" alt="Get QccPack at SourceForge.net. Fast, secure and Free Open Source software downloads" /></a></body></html>
