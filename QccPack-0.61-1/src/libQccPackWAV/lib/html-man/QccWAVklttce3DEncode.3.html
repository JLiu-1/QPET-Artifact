<!-- manual page source format generated by PolyglotMan v3.0.4, -->
<!-- available via anonymous ftp from ftp.cs.berkeley.edu:/ucb/people/phelps/tcltk/rman.tar.Z -->

<HTML>
<HEAD>
<TITLE>QccWAVklttce3DEncode.3</TITLE>
</HEAD>
<BODY>
<A HREF="#toc">Table of Contents</A><P>
 
<H2><A NAME="sect0" HREF="#toc0">NAME </A></H2>
QccWAVklttce3DEncode, QccWAVklttce3DDecode - encode/decode an image 
cube using the KLT+3D-TCE algorithm  
<H2><A NAME="sect1" HREF="#toc1">SYNOPSIS </A></H2>
<B>#include "libQccPack.h"</B>  <P>
<B>int 
QccWAVklttce3DEncode(const QccIMGImageCube *</B><I>image</I><B>, QccBitBuffer *</B><I>buffer</I><B>, 
int </B><I>num_levels</I><B>, double </B><I>alpha</I><B>, const QccWAVWavelet *</B><I>wavelet</I><B>, int </B><I>target_bit_cnt</I><B>);</B> 
 <P>
<B>int QccWAVklttce3DDecodeHeader(QccBitBuffer *</B><I>buffer</I><B>, int *</B><I>num_levels</I><B>, 
int *</B><I>num_frames</I><B>, int *</B><I>num_rows</I><B>, int *</B><I>num_cols</I><B>, int *</B><I>max_coefficient_bits</I><B>, 
double *</B><I>alpha</I><B>);</B>  <P>
<B>int QccWAVklttce3DDecode(QccBitBuffer *</B><I>buffer</I><B>, QccIMGImageCube 
*</B><I>image</I><B>, int </B><I>num_levels</I><B>, double </B><I>alpha</I><B>, const QccWAVWavelet *</B><I>wavelet</I><B>, int 
</B><I>max_coefficient_bits</I><B>, int </B><I>target_bit_bit</I><B>);</B>  
<H2><A NAME="sect2" HREF="#toc2">DESCRIPTION </A></H2>
 
<H3><A NAME="sect3" HREF="#toc3">Encoding </A></H3>
<P>
<B>QccWAVklttce3DEncode()</B> 
encodes an image cube, <I>image</I>, using a 3D generalization of the TCE algorithm 
that involves a KLT transform in one dimension and a dyadic DWT in the 
other two. See "ALGORITHM" below for more detail. <P>
<I>image</I> is the image cube 
to be coded and <I>buffer</I> is the output bitstream. <I>buffer</I> must be of <B>QCCBITBUFFER_OUTPUT</B> 
type and opened via a prior call to <B><A HREF="QccBitBufferStart.3.html">QccBitBufferStart</B>(3)</A>
. <P>
<B>QccWAVklttce3DEncode</B>() 
first applies a KLT in the spectral or temporal dimension of the image 
cube; subsequently, a dyadic DWT is applied spatially. <I>num_levels</I> give 
the number of levels of wavelet decomposition to perform. <I>wavelet</I> is the 
wavelet to use for decomposition. <P>
<B>QccWAVklttce3DEncode()</B> uses <B><A HREF="QccHYPkltTrain.3.html">QccHYPkltTrain</B>(3)</A>
 
and <B><A HREF="QccHYPkltTransform.3.html">QccHYPkltTransform</B>(3)</A>
 to train and apply, respectively, the spectral 
KLT. Then, <B><A HREF="QccWAVSubbandPyramid3DDWT.3.html">QccWAVSubbandPyramid3DDWT</B>(3)</A>
 with zero temporal decomposition 
levels is used to apply the spatial DWT to each frame of the image cube. 
<B>QccWAVklttce3DEncode()</B> embeds the KLT transform matrix into the output 
bitstream as overhead information. <P>
The KLT+3D-TCE algorithm performance 
is in part through the parameter <I>alpha</I>, a value that gives the learning 
rate of the density-estimation process implemented by the tarp filter used 
in one of the coding passes of the TCE algorithm. <P>
The bitstream output 
from the KLT+3D-TCE encoder is embedded, meaning that any prefix of the 
bitstream can be decoded to give a valid  representation of the image. 
 The KLT+3D-TCE encoder essentially produces output bits until the number 
of bits output reaches <I>target_bit_cnt</I>, the desired (target) total length 
of the output bitstream in bits, and then it stops. Note that this is the 
bitstream length in bits, not the rate of the bitstream (which would be 
expressed in bits per voxel). <P>
 
<H3><A NAME="sect4" HREF="#toc4">Decoding </A></H3>
<P>
<B>QccWAVklttce3DDecodeHeader()</B> decodes 
the header information  in a bitstream previously produced by <B>QccWAVklttce3DEncode()</B>. 
The input bitstream is <I>buffer</I> which must be of <B>QCCBITBUFFER_INPUT</B> type 
and opened via a prior call to <B><A HREF="QccBitBufferStart.3.html">QccBitBufferStart</B>(3)</A>
. <P>
The header information 
is returned in <I>num_levels</I> (number of levels of wavelet decomposition in 
the spatial directions), <I>num_frames</I> (size of the image cube in the temporal 
direction), <I>num_rows</I> (vertical size of image cube), <I>num_cols</I> (horizontal 
size of image cube), <I>max_coefficient_bits</I> (indicates the precision, in 
number of bits, of the wavelet coefficient with the largest magnitude), 
and <I>alpha</I> (the value of the learning rate). <P>
<B>QccWAVklttce3DDecode()</B> decodes 
the bitstream <I>buffer</I>, producing the reconstructed image cube, <I>image</I>. The 
bitstream must already have had its header read by a prior call to <B>QccWAVklttce3DDecodeHeader()</B> 
(i.e., you call <B>QccWAVklttce3DDecodeHeader() </B> first and then <B>QccWAVklttce3DDecode()</B>). 
If <I>target_bit_cnt</I> is <B>QCCENT_ANYNUMBITS</B>, then decoding stops when the end 
of the input bitstream is reached; otherwise, decoding stops when <I>target_num_bits</I> 
from the input bitstream have been decoded.  
<H2><A NAME="sect5" HREF="#toc5">ALGORITHM </A></H2>
The original TCE 
algorithm (see <B>QccWAVtce3DEncode()</B>) was developed for 2D images by Tian 
and Hemami; it was latter extended to 3D by Zhang <I>et al</I>. Zhang <I>et al</I>. considered 
two versions of 3D-TCE: one using a 3D wavelet transform (this is implemented 
here as <B><A HREF="QccWAVtce3DEncode.3.html">QccWAVtce3DEncode</B>(3)<B></A>
)</B> and one with a hybrid transform consisting 
of a spectral KLT followed by a spatial dyadic DWT (i.e., KLT+3D-TCE as implemented 
by <B>QccWAVklttce3DEncode()</B>).  
<H2><A NAME="sect6" HREF="#toc6">SEE ALSO </A></H2>
<B><A HREF="klttceencode3d.1.html">klttceencode3d</B>(1)</A>
, <B><A HREF="klttcedecode3d.1.html">klttcedecode3d</B>(1)</A>
, 
<B><A HREF="QccWAVtce3DEncode.3.html">QccWAVtce3DEncode</B>(3)</A>
, <B><A HREF="QccHYPkltTrain.3.html">QccHYPkltTrain</B>(3)</A>
, <B><A HREF="QccHYPkltTransform.3.html">QccHYPkltTransform</B>(3)</A>
, <B><A HREF="QccHYPklt.3.html">QccHYPklt</B>(3)</A>
, 
<B><A HREF="QccWAVSubbandPyramid3DDWT.3.html">QccWAVSubbandPyramid3DDWT</B>(3)</A>
, <B><A HREF="QccBitBuffer.3.html">QccBitBuffer</B>(3)</A>
, <B><A HREF="QccPackWAV.3.html">QccPackWAV</B>(3)</A>
, <B><A HREF="QccPackIMG.3.html">QccPackIMG</B>(3)</A>
, 
<B><A HREF="QccPack.3.html">QccPack</B>(3)</A>
 <P>
 <P>
J. Zhang, J. E. Fowler, and G. Liu, "Lossy-to-Lossless Compression 
of Hyperspectral Imagery Using 3D-TCE and an Integer KLT,"  <I>IEEE Geoscience 
and Remote Sensing Letters</I>, vol. 5, pp. 814-818, October 2008. <P>
 C. Tian and 
S. S. Hemami, "An Embedded Image Coding System Based on Tarp Filter with 
Classification," in <I>Proceedings of the International Conference on Acoustics, 
Speech, and Signal Processing</I>, Montreal, Quebec, Canada, May 2004, vol. 
3, pp. 49-52. <P>
  
<H2><A NAME="sect7" HREF="#toc7">AUTHOR </A></H2>
Copyright (C) 1997-2016  James E. Fowler <P>

<HR><P>
<A NAME="toc"><B>Table of Contents</B></A><P>
<UL>
<LI><A NAME="toc0" HREF="#sect0">NAME</A></LI>
<LI><A NAME="toc1" HREF="#sect1">SYNOPSIS</A></LI>
<LI><A NAME="toc2" HREF="#sect2">DESCRIPTION</A></LI>
<UL>
<LI><A NAME="toc3" HREF="#sect3">Encoding</A></LI>
<LI><A NAME="toc4" HREF="#sect4">Decoding</A></LI>
</UL>
<LI><A NAME="toc5" HREF="#sect5">ALGORITHM</A></LI>
<LI><A NAME="toc6" HREF="#sect6">SEE ALSO</A></LI>
<LI><A NAME="toc7" HREF="#sect7">AUTHOR</A></LI>
</UL>
<p><br><br><a href="http://sourceforge.net/projects/qccpack"><img src="http://sflogo.sourceforge.net/sflogo.php?group_id=5992&type=6" width="210" height="62" border="0" alt="Get QccPack at SourceForge.net. Fast, secure and Free Open Source software downloads" /></a></body></html>
